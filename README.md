# NLP Model Lab Examination Solutions üöÄ

This repository contains the complete Jupyter Notebook solutions for the Natural Language Processing (NLP) model lab examination. Each notebook is self-contained and includes all necessary steps to run the code.

## Quick Navigation to Solutions

The table below provides the full question for each problem and a direct link to its corresponding solution notebook.

| File Name | Full Question from Model Lab Exam | Navigation Link |
| :--- | :--- | :--- |
| **`1_brown_corpus_analysis.ipynb`** | Write a Python program to load the Brown Corpus from NLTK and perform word tokenization, POS tagging and frequency distribution of words. | [Go to Notebook](./1_brown_corpus_analysis.ipynb) |
| **`2_reuters_corpus_analysis.ipynb`** | Write a Python program to load the Reuters Corpus from NLTK and dispaly total categories in the corpus and perform sentence tokenization, POS tagging and frequency distribution of words. | [Go to Notebook](./2_reuters_corpus_analysis.ipynb) |
| **`3_wordnet_explorer.ipynb`** | Write a python code to load wordnet from NLTK and find all synonyms, antonyms, example and definitions of a given set of words (e.g., ‚Äúbank‚Äù, ‚Äúinterest‚Äù, ‚Äúmarket‚Äù) and perform POS tagging on the words and display their WordNet synsets according to their part of speech. | [Go to Notebook](./3_wordnet_explorer.ipynb) |
| **`4_text_analytics_framework.ipynb`** | Write a python program to work with text analytics framework. | [Go to Notebook](./4_text_analytics_framework.ipynb) |
| **`5_text_normalization.ipynb`** | Develop the Python code to perform text normalization on a sample text corpus. | [Go to Notebook](./5_text_normalization.ipynb) |
| **`6_tokenization_pos_correction.ipynb`** | Perform the text tokenization, POS tagging and obtain the corrected set of words from a sample document. | [Go to Notebook](./6_tokenization_pos_correction.ipynb) |
| **`7_normalization_pipeline.ipynb`** | Write the Python code to perform contraction expansion, stemming and lemmatization for the improper words obtained from a textual corpus. | [Go to Notebook](./7_normalization_pipeline.ipynb) |
| **`8_text_processing_dataset.ipynb`** | Develop the Python code to perform text processing for a sample dataset. | [Go to Notebook](./8_text_processing_dataset.ipynb) |
| **`9_four_normalization_techniques.ipynb`** | Design a Python code for any four text normalization techniques. | [Go to Notebook](./9_four_normalization_techniques.ipynb) |
| **`10_bow_binary_features.ipynb`** | Develop a sample text corpus and build a feature extraction model to extract features of text document in a corpus using bag of words model with binary feature. | [Go to Notebook](./10_bow_binary_features.ipynb) |
| **`11_bow_frequency_features.ipynb`** | Develop a sample text corpus and build a feature extraction model to extract features of text document in a corpus using bag of words model with frequency feature. | [Go to Notebook](./11_bow_frequency_features.ipynb) |
| **`12_tfidf_vectorization.ipynb`** | With a sample text corpus, design a feature extraction model to build the feature vector using TF-IDF vectorization. | [Go to Notebook](./12_tfidf_vectorization.ipynb) |
| **`13_binary_sentiment_classification.ipynb`** | Build an automated binary text classification system to classify the sample dataset into positive and negative feedback. | [Go to Notebook](./13_binary_sentiment_classification.ipynb) |
| **`14_spam_ham_classification.ipynb`** | Build an automated binary text classification system to classify the sample dataset into spam and ham emails. | [Go to Notebook](./14_spam_ham_classification.ipynb) |
| **`15_multiclass_classification.ipynb`** | Design a multiclass based text classification system to classify the text documents of a sample corpus into multiple classes.<br><br>*(Note: The solution uses the "Twitter US Airline Sentiment" dataset, originally from Kaggle.)* | [Go to Notebook](./15_multiclass_classification.ipynb) |
| **`16_text_summarization.ipynb`** | Build a text summary of a large text corpus using any text summarization technique. | [Go to Notebook](./16_text_summarization.ipynb) |
| **`17_topic_modeling_lsi.ipynb`** | Develop a topic modeling function to identify the topics from a textual document. Preprocess the documents to normalize them, extract features and use LSI topic model algorithm from gensim library. | [Go to Notebook](./17_topic_modeling_lsi.ipynb) |
| **`18_topic_modeling_lda.ipynb`** | Preprocess the documents to normalize them, extract features and use LDA topic model algorithm. | [Go to Notebook](./18_topic_modeling_lda.ipynb) |
| **`19_topic_modeling_nmf.ipynb`** | Preprocess the documents to normalize them, extract feature and use NNM topic model algorithm. | [Go to Notebook](./19_topic_modeling_nmf.ipynb) |
| **`20_topic_modeling_lda_sklearn.ipynb`** | Develop a topic modeling function to identify the topics from a textual document. Preprocess the documents to normalize them, extract features and use LDA topic model algorithm from sklearn library. | [Go to Notebook](./20_topic_modeling_lda_sklearn.ipynb) |
| **`21_cosine_similarity.ipynb`** | Write a Python program to compute the similarity between two sample sentences using cosine similarity. | [Go to Notebook](./21_cosine_similarity.ipynb) |
| **`22_euclidean_distance.ipynb`** | Write a Python program to calculate similarity using Euclidean distance. | [Go to Notebook](./22_euclidean_distance.ipynb) |

---
## How to Use This Repository

### 1. Clone the Repository
To get a local copy of these files, clone the repository using this command in your terminal or Git Bash:
```bash
git clone <your-repository-url>
