{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c7ac912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NLTK resources...\n",
      "Downloads complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tarru\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\tarru\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# !pip install scikit-learn nltk\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Download required NLTK data\n",
    "print(\"Downloading NLTK resources...\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "print(\"Downloads complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d33deb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b89d2524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original Corpus ---\n",
      "Sugar is bad to consume. My sister likes to have sugar, but not my father.\n",
      "My father spends a lot of time driving my sister around to dance practice.\n",
      "Doctors suggest that driving may cause increased stress and blood pressure.\n",
      "Sometimes I feel pressure to perform well at school, but my father never seems to drive my sister to do better.\n",
      "Health experts say that Sugar is not good for your lifestyle.\n"
     ]
    }
   ],
   "source": [
    "doc1 = \"Sugar is bad to consume. My sister likes to have sugar, but not my father.\"\n",
    "doc2 = \"My father spends a lot of time driving my sister around to dance practice.\"\n",
    "doc3 = \"Doctors suggest that driving may cause increased stress and blood pressure.\"\n",
    "doc4 = \"Sometimes I feel pressure to perform well at school, but my father never seems to drive my sister to do better.\"\n",
    "doc5 = \"Health experts say that Sugar is not good for your lifestyle.\"\n",
    "\n",
    "doc_complete = [doc1, doc2, doc3, doc4, doc5]\n",
    "\n",
    "print(\"--- Original Corpus ---\")\n",
    "for doc in doc_complete:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec7967be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processed Corpus (Cleaned Strings) ---\n",
      "sugar bad consume sister like sugar father\n",
      "father spends lot time driving sister around dance practice\n",
      "doctor suggest driving may cause increased stress blood pressure\n",
      "sometimes feel pressure perform well school father never seems drive sister better\n",
      "health expert say sugar good lifestyle\n"
     ]
    }
   ],
   "source": [
    "def preprocess_doc(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    clean_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in clean_tokens]\n",
    "    return \" \".join(lemmatized_tokens)\n",
    "\n",
    "doc_clean = [preprocess_doc(doc) for doc in doc_complete]\n",
    "\n",
    "print(\"\\n--- Processed Corpus (Cleaned Strings) ---\")\n",
    "for doc in doc_clean:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcf01d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Document-Term Matrix Shape ---\n",
      "(5, 5)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "\n",
    "doc_term_matrix = vectorizer.fit_transform(doc_clean)\n",
    "\n",
    "print(\"--- Document-Term Matrix Shape ---\")\n",
    "print(doc_term_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17ad31e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Model trained to find 2 topics.\n"
     ]
    }
   ],
   "source": [
    "num_topics = 2\n",
    "\n",
    "lda_model = LatentDirichletAllocation(\n",
    "    n_components=num_topics,\n",
    "    random_state=42\n",
    ")\n",
    "lda_model.fit(doc_term_matrix)\n",
    "\n",
    "print(f\"LDA Model trained to find {num_topics} topics.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44d66028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top 2 Topics Identified by LDA ---\n",
      "Topic 1:\n",
      "sugar father sister pressure\n",
      "Topic 2:\n",
      "driving pressure sister father\n"
     ]
    }
   ],
   "source": [
    "def display_topics(model, feature_names, num_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {topic_idx + 1}:\")\n",
    "        top_words = [feature_names[i] for i in topic.argsort()[:-num_top_words - 1:-1]]\n",
    "        print(\" \".join(top_words))\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(f\"\\n--- Top {num_topics} Topics Identified by LDA ---\")\n",
    "display_topics(lda_model, feature_names, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6e3d24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
