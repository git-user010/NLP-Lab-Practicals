{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9880b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NLTK resources...\n",
      "Downloads complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tarru\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\tarru\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# !pip install pandas nltk scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "print(\"Downloading NLTK resources...\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "print(\"Downloads complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02d6e9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "560e4d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- First 5 rows of the dataset ---\n",
      "  sentiment                                               text\n",
      "0   neutral                @VirginAmerica What @dhepburn said.\n",
      "1  positive  @VirginAmerica plus you've added commercials t...\n",
      "2   neutral  @VirginAmerica I didn't today... Must mean I n...\n",
      "3  negative  @VirginAmerica it's really aggressive to blast...\n",
      "4  negative  @VirginAmerica and it's a really big bad thing...\n",
      "\n",
      "--- Distribution of Sentiments ---\n",
      "negative    9178\n",
      "neutral     3099\n",
      "positive    2363\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "url = \"Tweets.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df = df[['airline_sentiment', 'text']]\n",
    "\n",
    "df.columns = ['sentiment', 'text']\n",
    "\n",
    "print(\"--- First 5 rows of the dataset ---\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n--- Distribution of Sentiments ---\")\n",
    "print(df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "557dfd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Dataset after Preprocessing ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>plus added commercial experience tacky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>today must mean need take another trip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>really aggressive blast obnoxious entertainmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>really big bad thing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                     processed_text\n",
       "0   neutral                                               said\n",
       "1  positive             plus added commercial experience tacky\n",
       "2   neutral             today must mean need take another trip\n",
       "3  negative  really aggressive blast obnoxious entertainmen...\n",
       "4  negative                               really big bad thing"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_tweet(text):\n",
    "    text = re.sub(r'(@\\w+|https://\\S+)', '', text)\n",
    "    \n",
    "    text = re.sub('[^a-zA-Z]', ' ', text).lower()\n",
    "    \n",
    "    tokens = text.split()\n",
    "    clean_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    return \" \".join(clean_tokens)\n",
    "\n",
    "df['processed_text'] = df['text'].apply(preprocess_tweet)\n",
    "\n",
    "print(\"--- Dataset after Preprocessing ---\")\n",
    "df[['sentiment', 'processed_text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55a3fcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (11712, 5000)\n",
      "Testing data shape: (2928, 5000)\n"
     ]
    }
   ],
   "source": [
    "X = df['processed_text']\n",
    "y = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"Training data shape: {X_train_tfidf.shape}\")\n",
    "print(f\"Testing data shape: {X_test_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7034b221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tarru\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tarru\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=1000)\n",
    "classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fb53257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Accuracy ---\n",
      "0.7725\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "          negative  neutral  positive\n",
      "negative      1741       69        25\n",
      "neutral        324      263        33\n",
      "positive       150       65       258\n",
      "\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.95      0.86      1835\n",
      "     neutral       0.66      0.42      0.52       620\n",
      "    positive       0.82      0.55      0.65       473\n",
      "\n",
      "    accuracy                           0.77      2928\n",
      "   macro avg       0.75      0.64      0.68      2928\n",
      "weighted avg       0.76      0.77      0.75      2928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"--- Model Accuracy ---\\n{accuracy:.4f}\\n\")\n",
    "\n",
    "labels = ['negative', 'neutral', 'positive']\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "df_cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "print(\"--- Confusion Matrix ---\")\n",
    "print(df_cm)\n",
    "\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "print(classification_report(y_test, y_pred, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdc4399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
